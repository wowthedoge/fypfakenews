{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/newswav/Documents/FYPFakeNews/fyp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>4490</td>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>8062</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>8622</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>4021</td>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>4330</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0      8476                       You Can Smell Hillary’s Fear   \n",
       "1     10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2      3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3     10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4       875   The Battle of New York: Why This Primary Matters   \n",
       "...     ...                                                ...   \n",
       "6330   4490  State Department says it can't find emails fro...   \n",
       "6331   8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332   8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333   4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334   4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"fake\"] = data['label'].apply(lambda x: 0 if x == \"REAL\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[\"title\"], data[\"fake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/distilbert-base-uncased/5e3f1108e3cb34ee048634875d8482665b65ac713291a7e32396fb18f6ff0063?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1710496722&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMDQ5NjcyMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9kaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZC81ZTNmMTEwOGUzY2IzNGVlMDQ4NjM0ODc1ZDg0ODI2NjViNjVhYzcxMzI5MWE3ZTMyMzk2ZmIxOGY2ZmYwMDYzP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiJ9XX0_&Signature=NrhfQ1P6CRXyKKt371BcQfp40HN-rwkYmIgONJJEQ2-yeT2pywRDg92oyJ2WCUclSCMZF5tj9je5UM1wTzoAD8UdDPLslCPR3yet9d%7EAD02R2oCZif0wtzidUsFHWQX056qkpOM8YrK%7Emirwje%7Esh89l2xPcjrbetBZZD5TreH6W2TgnS4zz9g1ZjGYJaM0syFpgAD6UKxnw8CMG-pr3SzqncvinqzeUgemHa-DadYw%7EcWlh-j9rrIznsXTbjcqRr%7EooC8ke3zNH%7EXzy0AkBofQPVmpbmJLi3SGA-ofTXxrkXChhLQcsREF7s-HrZDoUex6cPMC%7ETbgmtrc0yxQyRQ__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "# X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "# X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load the DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/newswav/Documents/FYPFakeNews/fyp/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7063254714012146\n",
      "Epoch 0, Loss: 0.703127920627594\n",
      "Epoch 0, Loss: 0.6827647089958191\n",
      "Epoch 0, Loss: 0.6642335653305054\n",
      "Epoch 0, Loss: 0.6687981486320496\n",
      "Epoch 0, Loss: 0.6992157697677612\n",
      "Epoch 0, Loss: 0.7021371722221375\n",
      "Epoch 0, Loss: 0.6436401605606079\n",
      "Epoch 0, Loss: 0.6330496072769165\n",
      "Epoch 0, Loss: 0.6883372664451599\n",
      "Epoch 0, Loss: 0.6454008221626282\n",
      "Epoch 0, Loss: 0.6444891095161438\n",
      "Epoch 0, Loss: 0.674267053604126\n",
      "Epoch 0, Loss: 0.6550200581550598\n",
      "Epoch 0, Loss: 0.6757447123527527\n",
      "Epoch 0, Loss: 0.6410918831825256\n",
      "Epoch 0, Loss: 0.6632018685340881\n",
      "Epoch 0, Loss: 0.5786011815071106\n",
      "Epoch 0, Loss: 0.6669766306877136\n",
      "Epoch 0, Loss: 0.547832190990448\n",
      "Epoch 0, Loss: 0.626020073890686\n",
      "Epoch 0, Loss: 0.49234673380851746\n",
      "Epoch 0, Loss: 0.5363789200782776\n",
      "Epoch 0, Loss: 0.6965688467025757\n",
      "Epoch 0, Loss: 0.5639642477035522\n",
      "Epoch 0, Loss: 0.5298178791999817\n",
      "Epoch 0, Loss: 0.5883207321166992\n",
      "Epoch 0, Loss: 0.568130373954773\n",
      "Epoch 0, Loss: 0.5052759647369385\n",
      "Epoch 0, Loss: 0.5185627341270447\n",
      "Epoch 0, Loss: 0.5536805987358093\n",
      "Epoch 0, Loss: 0.5005760788917542\n",
      "Epoch 0, Loss: 0.4895334839820862\n",
      "Epoch 0, Loss: 0.4406111538410187\n",
      "Epoch 0, Loss: 0.44692543148994446\n",
      "Epoch 0, Loss: 0.48064351081848145\n",
      "Epoch 0, Loss: 0.4747425317764282\n",
      "Epoch 0, Loss: 0.49152490496635437\n",
      "Epoch 0, Loss: 0.4134170413017273\n",
      "Epoch 0, Loss: 0.5635382533073425\n",
      "Epoch 0, Loss: 0.6505977511405945\n",
      "Epoch 0, Loss: 0.7689632773399353\n",
      "Epoch 0, Loss: 0.40428435802459717\n",
      "Epoch 0, Loss: 0.36241039633750916\n",
      "Epoch 0, Loss: 0.6911202073097229\n",
      "Epoch 0, Loss: 0.4490116834640503\n",
      "Epoch 0, Loss: 0.5079483389854431\n",
      "Epoch 0, Loss: 0.5980203747749329\n",
      "Epoch 0, Loss: 0.3768242597579956\n",
      "Epoch 0, Loss: 0.39408162236213684\n",
      "Epoch 0, Loss: 0.41419243812561035\n",
      "Epoch 0, Loss: 0.48916301131248474\n",
      "Epoch 0, Loss: 0.5042951703071594\n",
      "Epoch 0, Loss: 0.4225374460220337\n",
      "Epoch 0, Loss: 0.4769842326641083\n",
      "Epoch 0, Loss: 0.3861843943595886\n",
      "Epoch 0, Loss: 0.31068649888038635\n",
      "Epoch 0, Loss: 0.5375407934188843\n",
      "Epoch 0, Loss: 0.3867236375808716\n",
      "Epoch 0, Loss: 0.6148014664649963\n",
      "Epoch 0, Loss: 0.347391813993454\n",
      "Epoch 0, Loss: 0.46562620997428894\n",
      "Epoch 0, Loss: 0.33009612560272217\n",
      "Epoch 0, Loss: 0.5329556465148926\n",
      "Epoch 0, Loss: 0.45797857642173767\n",
      "Epoch 0, Loss: 0.4613513648509979\n",
      "Epoch 0, Loss: 0.438459187746048\n",
      "Epoch 0, Loss: 0.41788819432258606\n",
      "Epoch 0, Loss: 0.41068509221076965\n",
      "Epoch 0, Loss: 0.3776094317436218\n",
      "Epoch 0, Loss: 0.6541243195533752\n",
      "Epoch 0, Loss: 0.3976714015007019\n",
      "Epoch 0, Loss: 0.49684154987335205\n",
      "Epoch 0, Loss: 0.6921021938323975\n",
      "Epoch 0, Loss: 0.366507351398468\n",
      "Epoch 0, Loss: 0.46189743280410767\n",
      "Epoch 0, Loss: 0.6976511478424072\n",
      "Epoch 0, Loss: 0.4063434600830078\n",
      "Epoch 0, Loss: 0.49176642298698425\n",
      "Epoch 0, Loss: 0.4415566027164459\n",
      "Epoch 0, Loss: 0.32613253593444824\n",
      "Epoch 0, Loss: 0.5049561858177185\n",
      "Epoch 0, Loss: 0.529111921787262\n",
      "Epoch 0, Loss: 0.42053478956222534\n",
      "Epoch 0, Loss: 0.4154090881347656\n",
      "Epoch 0, Loss: 0.6013533473014832\n",
      "Epoch 0, Loss: 0.46466898918151855\n",
      "Epoch 0, Loss: 0.3801717460155487\n",
      "Epoch 0, Loss: 0.5944733023643494\n",
      "Epoch 0, Loss: 0.5210302472114563\n",
      "Epoch 0, Loss: 0.6671621203422546\n",
      "Epoch 0, Loss: 0.5234335064888\n",
      "Epoch 0, Loss: 0.4971659183502197\n",
      "Epoch 0, Loss: 0.3448426127433777\n",
      "Epoch 0, Loss: 0.4785809814929962\n",
      "Epoch 0, Loss: 0.432272732257843\n",
      "Epoch 0, Loss: 0.4044896364212036\n",
      "Epoch 0, Loss: 0.33223021030426025\n",
      "Epoch 0, Loss: 0.3561927378177643\n",
      "Epoch 0, Loss: 0.4397464990615845\n",
      "Epoch 0, Loss: 0.3595575988292694\n",
      "Epoch 0, Loss: 0.33739668130874634\n",
      "Epoch 0, Loss: 0.4387601315975189\n",
      "Epoch 0, Loss: 0.3722791373729706\n",
      "Epoch 0, Loss: 0.4366055130958557\n",
      "Epoch 0, Loss: 0.5517102479934692\n",
      "Epoch 0, Loss: 0.44476282596588135\n",
      "Epoch 0, Loss: 0.3690994679927826\n",
      "Epoch 0, Loss: 0.4187023639678955\n",
      "Epoch 0, Loss: 0.2330276072025299\n",
      "Epoch 0, Loss: 0.20801988244056702\n",
      "Epoch 0, Loss: 0.4172268509864807\n",
      "Epoch 0, Loss: 0.48017093539237976\n",
      "Epoch 0, Loss: 0.37263718247413635\n",
      "Epoch 0, Loss: 0.3754120171070099\n",
      "Epoch 0, Loss: 0.4569525122642517\n",
      "Epoch 0, Loss: 0.24070598185062408\n",
      "Epoch 0, Loss: 0.4177664816379547\n",
      "Epoch 0, Loss: 0.25162988901138306\n",
      "Epoch 0, Loss: 0.3566994369029999\n",
      "Epoch 0, Loss: 0.31635963916778564\n",
      "Epoch 0, Loss: 0.15407702326774597\n",
      "Epoch 0, Loss: 0.29779717326164246\n",
      "Epoch 0, Loss: 0.3368756175041199\n",
      "Epoch 0, Loss: 0.38997867703437805\n",
      "Epoch 0, Loss: 0.2972225546836853\n",
      "Epoch 0, Loss: 0.31316569447517395\n",
      "Epoch 0, Loss: 0.40544575452804565\n",
      "Epoch 0, Loss: 0.6094359755516052\n",
      "Epoch 0, Loss: 0.3435532748699188\n",
      "Epoch 0, Loss: 0.30326640605926514\n",
      "Epoch 0, Loss: 0.43586307764053345\n",
      "Epoch 0, Loss: 0.391720712184906\n",
      "Epoch 0, Loss: 0.5361216068267822\n",
      "Epoch 0, Loss: 0.2904333174228668\n",
      "Epoch 0, Loss: 0.3421778082847595\n",
      "Epoch 0, Loss: 0.290233314037323\n",
      "Epoch 0, Loss: 0.3305407464504242\n",
      "Epoch 0, Loss: 0.3387201130390167\n",
      "Epoch 0, Loss: 0.20760639011859894\n",
      "Epoch 0, Loss: 0.36554834246635437\n",
      "Epoch 0, Loss: 0.42980271577835083\n",
      "Epoch 0, Loss: 0.2659832835197449\n",
      "Epoch 0, Loss: 0.34127023816108704\n",
      "Epoch 0, Loss: 0.43305981159210205\n",
      "Epoch 0, Loss: 0.35644587874412537\n",
      "Epoch 0, Loss: 0.3859114944934845\n",
      "Epoch 0, Loss: 0.3135947287082672\n",
      "Epoch 0, Loss: 0.4683144986629486\n",
      "Epoch 0, Loss: 0.2901448905467987\n",
      "Epoch 0, Loss: 0.4337315261363983\n",
      "Epoch 0, Loss: 0.44244030117988586\n",
      "Epoch 0, Loss: 0.32245445251464844\n",
      "Epoch 0, Loss: 0.4233283996582031\n",
      "Epoch 0, Loss: 0.3725622296333313\n",
      "Epoch 0, Loss: 0.37417200207710266\n",
      "Epoch 0, Loss: 0.35708853602409363\n",
      "Epoch 0, Loss: 0.28857848048210144\n",
      "Epoch 0, Loss: 0.4181298613548279\n",
      "Epoch 0, Loss: 0.30428746342658997\n",
      "Epoch 0, Loss: 0.3937605023384094\n",
      "Epoch 0, Loss: 0.26648133993148804\n",
      "Epoch 0, Loss: 0.5145734548568726\n",
      "Epoch 0, Loss: 0.34148895740509033\n",
      "Epoch 0, Loss: 0.3195846378803253\n",
      "Epoch 0, Loss: 0.2060903161764145\n",
      "Epoch 0, Loss: 0.3642834722995758\n",
      "Epoch 0, Loss: 0.22680950164794922\n",
      "Epoch 0, Loss: 0.42692479491233826\n",
      "Epoch 0, Loss: 0.2918753921985626\n",
      "Epoch 0, Loss: 0.3418627977371216\n",
      "Epoch 0, Loss: 0.440523624420166\n",
      "Epoch 0, Loss: 0.3302987217903137\n",
      "Epoch 0, Loss: 0.30699580907821655\n",
      "Epoch 0, Loss: 0.45334240794181824\n",
      "Epoch 0, Loss: 0.5899004936218262\n",
      "Epoch 0, Loss: 0.37439268827438354\n",
      "Epoch 0, Loss: 0.6211928129196167\n",
      "Epoch 0, Loss: 0.29065561294555664\n",
      "Epoch 0, Loss: 0.3039613366127014\n",
      "Epoch 0, Loss: 0.3225817382335663\n",
      "Epoch 0, Loss: 0.268311083316803\n",
      "Epoch 0, Loss: 0.28126367926597595\n",
      "Epoch 0, Loss: 0.3542569577693939\n",
      "Epoch 0, Loss: 0.5271005630493164\n",
      "Epoch 0, Loss: 0.28710275888442993\n",
      "Epoch 0, Loss: 0.28289148211479187\n",
      "Epoch 0, Loss: 0.4222591817378998\n",
      "Epoch 0, Loss: 0.40276363492012024\n",
      "Epoch 0, Loss: 0.4188497066497803\n",
      "Epoch 0, Loss: 0.2898241877555847\n",
      "Epoch 0, Loss: 0.28531613945961\n",
      "Epoch 0, Loss: 0.2879140377044678\n",
      "Epoch 0, Loss: 0.36367836594581604\n",
      "Epoch 0, Loss: 0.48780086636543274\n",
      "Epoch 0, Loss: 0.3198072016239166\n",
      "Epoch 0, Loss: 0.3214157819747925\n",
      "Epoch 0, Loss: 0.36017805337905884\n",
      "Epoch 1, Loss: 0.1385934054851532\n",
      "Epoch 1, Loss: 0.21153473854064941\n",
      "Epoch 1, Loss: 0.3491610884666443\n",
      "Epoch 1, Loss: 0.23816926777362823\n",
      "Epoch 1, Loss: 0.3078592121601105\n",
      "Epoch 1, Loss: 0.16400490701198578\n",
      "Epoch 1, Loss: 0.10980547219514847\n",
      "Epoch 1, Loss: 0.21384011209011078\n",
      "Epoch 1, Loss: 0.45299723744392395\n",
      "Epoch 1, Loss: 0.11069151014089584\n",
      "Epoch 1, Loss: 0.18923388421535492\n",
      "Epoch 1, Loss: 0.07621978223323822\n",
      "Epoch 1, Loss: 0.15868300199508667\n",
      "Epoch 1, Loss: 0.2916404902935028\n",
      "Epoch 1, Loss: 0.5492228865623474\n",
      "Epoch 1, Loss: 0.24990953505039215\n",
      "Epoch 1, Loss: 0.15075545012950897\n",
      "Epoch 1, Loss: 0.40208807587623596\n",
      "Epoch 1, Loss: 0.3935536742210388\n",
      "Epoch 1, Loss: 0.17372381687164307\n",
      "Epoch 1, Loss: 0.3516078591346741\n",
      "Epoch 1, Loss: 0.3379151523113251\n",
      "Epoch 1, Loss: 0.2755517363548279\n",
      "Epoch 1, Loss: 0.10766904801130295\n",
      "Epoch 1, Loss: 0.25648239254951477\n",
      "Epoch 1, Loss: 0.24072743952274323\n",
      "Epoch 1, Loss: 0.26076069474220276\n",
      "Epoch 1, Loss: 0.4707946479320526\n",
      "Epoch 1, Loss: 0.17704682052135468\n",
      "Epoch 1, Loss: 0.17801600694656372\n",
      "Epoch 1, Loss: 0.22891712188720703\n",
      "Epoch 1, Loss: 0.2754267156124115\n",
      "Epoch 1, Loss: 0.21837104856967926\n",
      "Epoch 1, Loss: 0.181847482919693\n",
      "Epoch 1, Loss: 0.21983160078525543\n",
      "Epoch 1, Loss: 0.1568991243839264\n",
      "Epoch 1, Loss: 0.27152857184410095\n",
      "Epoch 1, Loss: 0.11113304644823074\n",
      "Epoch 1, Loss: 0.1305479109287262\n",
      "Epoch 1, Loss: 0.25642991065979004\n",
      "Epoch 1, Loss: 0.21552437543869019\n",
      "Epoch 1, Loss: 0.19250930845737457\n",
      "Epoch 1, Loss: 0.2075076401233673\n",
      "Epoch 1, Loss: 0.21474531292915344\n",
      "Epoch 1, Loss: 0.14473393559455872\n",
      "Epoch 1, Loss: 0.12548044323921204\n",
      "Epoch 1, Loss: 0.16557946801185608\n",
      "Epoch 1, Loss: 0.1713181436061859\n",
      "Epoch 1, Loss: 0.30527180433273315\n",
      "Epoch 1, Loss: 0.23299551010131836\n",
      "Epoch 1, Loss: 0.1649998426437378\n",
      "Epoch 1, Loss: 0.08459675312042236\n",
      "Epoch 1, Loss: 0.12099436670541763\n",
      "Epoch 1, Loss: 0.1987495869398117\n",
      "Epoch 1, Loss: 0.1683446615934372\n",
      "Epoch 1, Loss: 0.09143072366714478\n",
      "Epoch 1, Loss: 0.2625667154788971\n",
      "Epoch 1, Loss: 0.1914326250553131\n",
      "Epoch 1, Loss: 0.3725138306617737\n",
      "Epoch 1, Loss: 0.22388707101345062\n",
      "Epoch 1, Loss: 0.2020365297794342\n",
      "Epoch 1, Loss: 0.22560791671276093\n",
      "Epoch 1, Loss: 0.23610393702983856\n",
      "Epoch 1, Loss: 0.202194482088089\n",
      "Epoch 1, Loss: 0.3525144159793854\n",
      "Epoch 1, Loss: 0.17557333409786224\n",
      "Epoch 1, Loss: 0.6272801756858826\n",
      "Epoch 1, Loss: 0.07644899934530258\n",
      "Epoch 1, Loss: 0.33891984820365906\n",
      "Epoch 1, Loss: 0.19636210799217224\n",
      "Epoch 1, Loss: 0.2123972773551941\n",
      "Epoch 1, Loss: 0.1919471174478531\n",
      "Epoch 1, Loss: 0.2513456344604492\n",
      "Epoch 1, Loss: 0.16445276141166687\n",
      "Epoch 1, Loss: 0.13147172331809998\n",
      "Epoch 1, Loss: 0.198215052485466\n",
      "Epoch 1, Loss: 0.18443070352077484\n",
      "Epoch 1, Loss: 0.13120512664318085\n",
      "Epoch 1, Loss: 0.477733314037323\n",
      "Epoch 1, Loss: 0.24433784186840057\n",
      "Epoch 1, Loss: 0.2584828734397888\n",
      "Epoch 1, Loss: 0.08471380174160004\n",
      "Epoch 1, Loss: 0.29554465413093567\n",
      "Epoch 1, Loss: 0.315615177154541\n",
      "Epoch 1, Loss: 0.28807657957077026\n",
      "Epoch 1, Loss: 0.1671934425830841\n",
      "Epoch 1, Loss: 0.11296984553337097\n",
      "Epoch 1, Loss: 0.08870841562747955\n",
      "Epoch 1, Loss: 0.19592858850955963\n",
      "Epoch 1, Loss: 0.2268892228603363\n",
      "Epoch 1, Loss: 0.2319372147321701\n",
      "Epoch 1, Loss: 0.21674969792366028\n",
      "Epoch 1, Loss: 0.09654492884874344\n",
      "Epoch 1, Loss: 0.06914310902357101\n",
      "Epoch 1, Loss: 0.21504659950733185\n",
      "Epoch 1, Loss: 0.23692549765110016\n",
      "Epoch 1, Loss: 0.09921339899301529\n",
      "Epoch 1, Loss: 0.18298093974590302\n",
      "Epoch 1, Loss: 0.12442729622125626\n",
      "Epoch 1, Loss: 0.3436703681945801\n",
      "Epoch 1, Loss: 0.3507165014743805\n",
      "Epoch 1, Loss: 0.16121210157871246\n",
      "Epoch 1, Loss: 0.40870246291160583\n",
      "Epoch 1, Loss: 0.2468697428703308\n",
      "Epoch 1, Loss: 0.20225879549980164\n",
      "Epoch 1, Loss: 0.3038958013057709\n",
      "Epoch 1, Loss: 0.182150200009346\n",
      "Epoch 1, Loss: 0.10849481076002121\n",
      "Epoch 1, Loss: 0.37625235319137573\n",
      "Epoch 1, Loss: 0.14645348489284515\n",
      "Epoch 1, Loss: 0.25398892164230347\n",
      "Epoch 1, Loss: 0.09888213872909546\n",
      "Epoch 1, Loss: 0.298051655292511\n",
      "Epoch 1, Loss: 0.12295807152986526\n",
      "Epoch 1, Loss: 0.2453075796365738\n",
      "Epoch 1, Loss: 0.10069111734628677\n",
      "Epoch 1, Loss: 0.14941191673278809\n",
      "Epoch 1, Loss: 0.3088361918926239\n",
      "Epoch 1, Loss: 0.23061153292655945\n",
      "Epoch 1, Loss: 0.12482495605945587\n",
      "Epoch 1, Loss: 0.16583597660064697\n",
      "Epoch 1, Loss: 0.22312220931053162\n",
      "Epoch 1, Loss: 0.14991167187690735\n",
      "Epoch 1, Loss: 0.22526028752326965\n",
      "Epoch 1, Loss: 0.13502904772758484\n",
      "Epoch 1, Loss: 0.17709723114967346\n",
      "Epoch 1, Loss: 0.24542838335037231\n",
      "Epoch 1, Loss: 0.2008018046617508\n",
      "Epoch 1, Loss: 0.12961435317993164\n",
      "Epoch 1, Loss: 0.3176540732383728\n",
      "Epoch 1, Loss: 0.3468497693538666\n",
      "Epoch 1, Loss: 0.21917173266410828\n",
      "Epoch 1, Loss: 0.2516455352306366\n",
      "Epoch 1, Loss: 0.1361778825521469\n",
      "Epoch 1, Loss: 0.3142532408237457\n",
      "Epoch 1, Loss: 0.20000045001506805\n",
      "Epoch 1, Loss: 0.22111403942108154\n",
      "Epoch 1, Loss: 0.15523818135261536\n",
      "Epoch 1, Loss: 0.30760514736175537\n",
      "Epoch 1, Loss: 0.10824503749608994\n",
      "Epoch 1, Loss: 0.269253134727478\n",
      "Epoch 1, Loss: 0.24433138966560364\n",
      "Epoch 1, Loss: 0.10519135743379593\n",
      "Epoch 1, Loss: 0.09714417904615402\n",
      "Epoch 1, Loss: 0.20835548639297485\n",
      "Epoch 1, Loss: 0.2915358543395996\n",
      "Epoch 1, Loss: 0.13402318954467773\n",
      "Epoch 1, Loss: 0.25899815559387207\n",
      "Epoch 1, Loss: 0.23461014032363892\n",
      "Epoch 1, Loss: 0.11500375717878342\n",
      "Epoch 1, Loss: 0.09739699959754944\n",
      "Epoch 1, Loss: 0.10910070687532425\n",
      "Epoch 1, Loss: 0.209848091006279\n",
      "Epoch 1, Loss: 0.19094939529895782\n",
      "Epoch 1, Loss: 0.295166552066803\n",
      "Epoch 1, Loss: 0.42166680097579956\n",
      "Epoch 1, Loss: 0.2445722222328186\n",
      "Epoch 1, Loss: 0.22287891805171967\n",
      "Epoch 1, Loss: 0.23008045554161072\n",
      "Epoch 1, Loss: 0.14093871414661407\n",
      "Epoch 1, Loss: 0.21230214834213257\n",
      "Epoch 1, Loss: 0.31542301177978516\n",
      "Epoch 1, Loss: 0.11319315433502197\n",
      "Epoch 1, Loss: 0.1504560261964798\n",
      "Epoch 1, Loss: 0.15566107630729675\n",
      "Epoch 1, Loss: 0.2530730068683624\n",
      "Epoch 1, Loss: 0.057180698961019516\n",
      "Epoch 1, Loss: 0.1182849258184433\n",
      "Epoch 1, Loss: 0.24931778013706207\n",
      "Epoch 1, Loss: 0.18557044863700867\n",
      "Epoch 1, Loss: 0.30770769715309143\n",
      "Epoch 1, Loss: 0.25208747386932373\n",
      "Epoch 1, Loss: 0.27331873774528503\n",
      "Epoch 1, Loss: 0.10603558272123337\n",
      "Epoch 1, Loss: 0.41312772035598755\n",
      "Epoch 1, Loss: 0.4262486696243286\n",
      "Epoch 1, Loss: 0.2430180460214615\n",
      "Epoch 1, Loss: 0.16443029046058655\n",
      "Epoch 1, Loss: 0.5132746696472168\n",
      "Epoch 1, Loss: 0.4034210741519928\n",
      "Epoch 1, Loss: 0.19617125391960144\n",
      "Epoch 1, Loss: 0.2443007230758667\n",
      "Epoch 1, Loss: 0.2995658814907074\n",
      "Epoch 1, Loss: 0.1801755726337433\n",
      "Epoch 1, Loss: 0.2561032176017761\n",
      "Epoch 1, Loss: 0.28273093700408936\n",
      "Epoch 1, Loss: 0.3508906066417694\n",
      "Epoch 1, Loss: 0.24724219739437103\n",
      "Epoch 1, Loss: 0.19668413698673248\n",
      "Epoch 1, Loss: 0.27418625354766846\n",
      "Epoch 1, Loss: 0.18872962892055511\n",
      "Epoch 1, Loss: 0.32557758688926697\n",
      "Epoch 1, Loss: 0.12219580262899399\n",
      "Epoch 1, Loss: 0.1335742175579071\n",
      "Epoch 1, Loss: 0.24541407823562622\n",
      "Epoch 1, Loss: 0.16685640811920166\n",
      "Epoch 1, Loss: 0.20782576501369476\n",
      "Epoch 1, Loss: 0.36130112409591675\n",
      "Epoch 2, Loss: 0.07304763048887253\n",
      "Epoch 2, Loss: 0.03350995108485222\n",
      "Epoch 2, Loss: 0.04963354766368866\n",
      "Epoch 2, Loss: 0.1339668482542038\n",
      "Epoch 2, Loss: 0.03784598782658577\n",
      "Epoch 2, Loss: 0.05749669671058655\n",
      "Epoch 2, Loss: 0.12477154284715652\n",
      "Epoch 2, Loss: 0.0666499212384224\n",
      "Epoch 2, Loss: 0.08424940705299377\n",
      "Epoch 2, Loss: 0.04826913774013519\n",
      "Epoch 2, Loss: 0.09000648558139801\n",
      "Epoch 2, Loss: 0.08783210068941116\n",
      "Epoch 2, Loss: 0.019772373139858246\n",
      "Epoch 2, Loss: 0.008532927371561527\n",
      "Epoch 2, Loss: 0.04121162369847298\n",
      "Epoch 2, Loss: 0.05492690950632095\n",
      "Epoch 2, Loss: 0.32197144627571106\n",
      "Epoch 2, Loss: 0.008182869292795658\n",
      "Epoch 2, Loss: 0.20722892880439758\n",
      "Epoch 2, Loss: 0.06668875366449356\n",
      "Epoch 2, Loss: 0.04920673370361328\n",
      "Epoch 2, Loss: 0.124931201338768\n",
      "Epoch 2, Loss: 0.06713661551475525\n",
      "Epoch 2, Loss: 0.023207789286971092\n",
      "Epoch 2, Loss: 0.05122874304652214\n",
      "Epoch 2, Loss: 0.13569693267345428\n",
      "Epoch 2, Loss: 0.041152141988277435\n",
      "Epoch 2, Loss: 0.14241863787174225\n",
      "Epoch 2, Loss: 0.01494341529905796\n",
      "Epoch 2, Loss: 0.009044193662703037\n",
      "Epoch 2, Loss: 0.014117619954049587\n",
      "Epoch 2, Loss: 0.07112640142440796\n",
      "Epoch 2, Loss: 0.06598340719938278\n",
      "Epoch 2, Loss: 0.29125458002090454\n",
      "Epoch 2, Loss: 0.013436807319521904\n",
      "Epoch 2, Loss: 0.1383415013551712\n",
      "Epoch 2, Loss: 0.24435873329639435\n",
      "Epoch 2, Loss: 0.35203641653060913\n",
      "Epoch 2, Loss: 0.10036679357290268\n",
      "Epoch 2, Loss: 0.012949450872838497\n",
      "Epoch 2, Loss: 0.0757284164428711\n",
      "Epoch 2, Loss: 0.062402088195085526\n",
      "Epoch 2, Loss: 0.02124391309916973\n",
      "Epoch 2, Loss: 0.05953603237867355\n",
      "Epoch 2, Loss: 0.10296256840229034\n",
      "Epoch 2, Loss: 0.08745986223220825\n",
      "Epoch 2, Loss: 0.10409922897815704\n",
      "Epoch 2, Loss: 0.025520797818899155\n",
      "Epoch 2, Loss: 0.0207950621843338\n",
      "Epoch 2, Loss: 0.079252228140831\n",
      "Epoch 2, Loss: 0.09164034575223923\n",
      "Epoch 2, Loss: 0.05148320272564888\n",
      "Epoch 2, Loss: 0.06106032431125641\n",
      "Epoch 2, Loss: 0.18270622193813324\n",
      "Epoch 2, Loss: 0.020359646528959274\n",
      "Epoch 2, Loss: 0.181684210896492\n",
      "Epoch 2, Loss: 0.06029318645596504\n",
      "Epoch 2, Loss: 0.03822753205895424\n",
      "Epoch 2, Loss: 0.18294568359851837\n",
      "Epoch 2, Loss: 0.008082465268671513\n",
      "Epoch 2, Loss: 0.12778155505657196\n",
      "Epoch 2, Loss: 0.025143660604953766\n",
      "Epoch 2, Loss: 0.09014192223548889\n",
      "Epoch 2, Loss: 0.028171947225928307\n",
      "Epoch 2, Loss: 0.03764292225241661\n",
      "Epoch 2, Loss: 0.08189112693071365\n",
      "Epoch 2, Loss: 0.10786538571119308\n",
      "Epoch 2, Loss: 0.19113437831401825\n",
      "Epoch 2, Loss: 0.1304425150156021\n",
      "Epoch 2, Loss: 0.17735157907009125\n",
      "Epoch 2, Loss: 0.01804955117404461\n",
      "Epoch 2, Loss: 0.11956388503313065\n",
      "Epoch 2, Loss: 0.20482748746871948\n",
      "Epoch 2, Loss: 0.20020994544029236\n",
      "Epoch 2, Loss: 0.0387699156999588\n",
      "Epoch 2, Loss: 0.3702264130115509\n",
      "Epoch 2, Loss: 0.020157935097813606\n",
      "Epoch 2, Loss: 0.028223827481269836\n",
      "Epoch 2, Loss: 0.042409058660268784\n",
      "Epoch 2, Loss: 0.08732868731021881\n",
      "Epoch 2, Loss: 0.15024761855602264\n",
      "Epoch 2, Loss: 0.14479367434978485\n",
      "Epoch 2, Loss: 0.03441132977604866\n",
      "Epoch 2, Loss: 0.06606646627187729\n",
      "Epoch 2, Loss: 0.0848904475569725\n",
      "Epoch 2, Loss: 0.05282869189977646\n",
      "Epoch 2, Loss: 0.1224580779671669\n",
      "Epoch 2, Loss: 0.1135430783033371\n",
      "Epoch 2, Loss: 0.017666002735495567\n",
      "Epoch 2, Loss: 0.04142466560006142\n",
      "Epoch 2, Loss: 0.24762064218521118\n",
      "Epoch 2, Loss: 0.019479719921946526\n",
      "Epoch 2, Loss: 0.03282194212079048\n",
      "Epoch 2, Loss: 0.028676146641373634\n",
      "Epoch 2, Loss: 0.0715877115726471\n",
      "Epoch 2, Loss: 0.0505298487842083\n",
      "Epoch 2, Loss: 0.03189733996987343\n",
      "Epoch 2, Loss: 0.06863025575876236\n",
      "Epoch 2, Loss: 0.046308115124702454\n",
      "Epoch 2, Loss: 0.01914690062403679\n",
      "Epoch 2, Loss: 0.05965114384889603\n",
      "Epoch 2, Loss: 0.020281970500946045\n",
      "Epoch 2, Loss: 0.06914838403463364\n",
      "Epoch 2, Loss: 0.10456059873104095\n",
      "Epoch 2, Loss: 0.16221286356449127\n",
      "Epoch 2, Loss: 0.07615925371646881\n",
      "Epoch 2, Loss: 0.016991879791021347\n",
      "Epoch 2, Loss: 0.01510869525372982\n",
      "Epoch 2, Loss: 0.02963685244321823\n",
      "Epoch 2, Loss: 0.18782766163349152\n",
      "Epoch 2, Loss: 0.06830865144729614\n",
      "Epoch 2, Loss: 0.04683316498994827\n",
      "Epoch 2, Loss: 0.012589717283844948\n",
      "Epoch 2, Loss: 0.15116718411445618\n",
      "Epoch 2, Loss: 0.008837349712848663\n",
      "Epoch 2, Loss: 0.036292605102062225\n",
      "Epoch 2, Loss: 0.057380013167858124\n",
      "Epoch 2, Loss: 0.17267175018787384\n",
      "Epoch 2, Loss: 0.14884717762470245\n",
      "Epoch 2, Loss: 0.014581969007849693\n",
      "Epoch 2, Loss: 0.016452442854642868\n",
      "Epoch 2, Loss: 0.022824693471193314\n",
      "Epoch 2, Loss: 0.09856954962015152\n",
      "Epoch 2, Loss: 0.01833261176943779\n",
      "Epoch 2, Loss: 0.16427138447761536\n",
      "Epoch 2, Loss: 0.1472470909357071\n",
      "Epoch 2, Loss: 0.05929490178823471\n",
      "Epoch 2, Loss: 0.19205604493618011\n",
      "Epoch 2, Loss: 0.004902542568743229\n",
      "Epoch 2, Loss: 0.02313115820288658\n",
      "Epoch 2, Loss: 0.08491896837949753\n",
      "Epoch 2, Loss: 0.0366777703166008\n",
      "Epoch 2, Loss: 0.0488581508398056\n",
      "Epoch 2, Loss: 0.020477812737226486\n",
      "Epoch 2, Loss: 0.012070635333657265\n",
      "Epoch 2, Loss: 0.1043146550655365\n",
      "Epoch 2, Loss: 0.09417848289012909\n",
      "Epoch 2, Loss: 0.12232454866170883\n",
      "Epoch 2, Loss: 0.06520775705575943\n",
      "Epoch 2, Loss: 0.03622093424201012\n",
      "Epoch 2, Loss: 0.0599103644490242\n",
      "Epoch 2, Loss: 0.03513330593705177\n",
      "Epoch 2, Loss: 0.3397640585899353\n",
      "Epoch 2, Loss: 0.05177630856633186\n",
      "Epoch 2, Loss: 0.020837945863604546\n",
      "Epoch 2, Loss: 0.14373742043972015\n",
      "Epoch 2, Loss: 0.021437935531139374\n",
      "Epoch 2, Loss: 0.018229443579912186\n",
      "Epoch 2, Loss: 0.028084957972168922\n",
      "Epoch 2, Loss: 0.008165910840034485\n",
      "Epoch 2, Loss: 0.019346263259649277\n",
      "Epoch 2, Loss: 0.016100624576210976\n",
      "Epoch 2, Loss: 0.04916444420814514\n",
      "Epoch 2, Loss: 0.08576000481843948\n",
      "Epoch 2, Loss: 0.2290138602256775\n",
      "Epoch 2, Loss: 0.24328362941741943\n",
      "Epoch 2, Loss: 0.0768633633852005\n",
      "Epoch 2, Loss: 0.08580908924341202\n",
      "Epoch 2, Loss: 0.017646174877882004\n",
      "Epoch 2, Loss: 0.014293450862169266\n",
      "Epoch 2, Loss: 0.1768263280391693\n",
      "Epoch 2, Loss: 0.03531179577112198\n",
      "Epoch 2, Loss: 0.04843475669622421\n",
      "Epoch 2, Loss: 0.2908143401145935\n",
      "Epoch 2, Loss: 0.05656476318836212\n",
      "Epoch 2, Loss: 0.16897475719451904\n",
      "Epoch 2, Loss: 0.01954510249197483\n",
      "Epoch 2, Loss: 0.02918417751789093\n",
      "Epoch 2, Loss: 0.06681329011917114\n",
      "Epoch 2, Loss: 0.2436501681804657\n",
      "Epoch 2, Loss: 0.32019951939582825\n",
      "Epoch 2, Loss: 0.039340194314718246\n",
      "Epoch 2, Loss: 0.048345278948545456\n",
      "Epoch 2, Loss: 0.1427595317363739\n",
      "Epoch 2, Loss: 0.015729211270809174\n",
      "Epoch 2, Loss: 0.1427234560251236\n",
      "Epoch 2, Loss: 0.1486358493566513\n",
      "Epoch 2, Loss: 0.04263211041688919\n",
      "Epoch 2, Loss: 0.12705399096012115\n",
      "Epoch 2, Loss: 0.1271107792854309\n",
      "Epoch 2, Loss: 0.16785573959350586\n",
      "Epoch 2, Loss: 0.047337375581264496\n",
      "Epoch 2, Loss: 0.03337480127811432\n",
      "Epoch 2, Loss: 0.05058012157678604\n",
      "Epoch 2, Loss: 0.021324174478650093\n",
      "Epoch 2, Loss: 0.13718214631080627\n",
      "Epoch 2, Loss: 0.1563267707824707\n",
      "Epoch 2, Loss: 0.07608836889266968\n",
      "Epoch 2, Loss: 0.050734519958496094\n",
      "Epoch 2, Loss: 0.05478881672024727\n",
      "Epoch 2, Loss: 0.12071456015110016\n",
      "Epoch 2, Loss: 0.16604135930538177\n",
      "Epoch 2, Loss: 0.23516231775283813\n",
      "Epoch 2, Loss: 0.1339423954486847\n",
      "Epoch 2, Loss: 0.2604719400405884\n",
      "Epoch 2, Loss: 0.025038471445441246\n",
      "Epoch 2, Loss: 0.07293888181447983\n",
      "Epoch 2, Loss: 0.019187552854418755\n"
     ]
    }
   ],
   "source": [
    "# clf = LinearSVC()\n",
    "# clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "\n",
    "# Use the tokenizer in the same way as before\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Assuming data[\"title\"] and y are prepared\n",
    "X_encoded = encode_texts(data[\"title\"].tolist())\n",
    "\n",
    "# Prepare the dataset and DataLoader\n",
    "dataset = TensorDataset(X_encoded['input_ids'], X_encoded['attention_mask'], torch.tensor(y, dtype=torch.long))\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in loader:\n",
    "        batch_input_ids, batch_attention_mask, batch_labels = batch\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, labels=batch_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./my_distilbert_model/tokenizer_config.json',\n",
       " './my_distilbert_model/special_tokens_map.json',\n",
       " './my_distilbert_model/vocab.txt',\n",
       " './my_distilbert_model/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./my_distilbert_model')\n",
    "tokenizer.save_pretrained('./my_distilbert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequenceClassifierOutput' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Assuming 'texts' is a list of strings from your dataset\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m embeddings_np \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m embeddings\n",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Use the mean pooling strategy to get a single vector for each input\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SequenceClassifierOutput' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"mytext.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    # Tokenize texts and prepare input tensors\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    # Generate embeddings with DistilBERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the mean pooling strategy to get a single vector for each input\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Assuming 'texts' is a list of strings from your dataset\n",
    "embeddings = get_embeddings([text])\n",
    "\n",
    "embeddings_np = embeddings.numpy() if isinstance(embeddings, torch.Tensor) else embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
